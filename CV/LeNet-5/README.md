# LeNet-5 Architecture

## Contents

* [implementation](model.py)

## Summary

![1lvvWF48t7cyRWqct13eU0w](https://user-images.githubusercontent.com/89085916/169703526-470d969e-1d8b-49eb-b69c-311374cd8a24.jpg)

### Network Architecture

he first layer is the input layer with feature map size 32X32X1. Then we have the first convolution layer with 6 filters of size 5X5 and stride is 1. The activation function used at his layer is tanh. The output feature map is  28X28X6.
Next, we have an average pooling layer with filter size 2X2 and stride 1. The resulting feature map is 14X14X6. Since the pooling layer doesnâ€™t affect the number of channels. After this comes the second convolution layer with 16 filters of 5X5 and stride 1. Also, the activation function is tanh. Now the output size is 10X10X16. Again comes the other average pooling layer of 2X2 with stride 2. As a result, the size of the feature map reduced to 5X5X16.
The final pooling layer has 120 filters of 5X5  with stride 1 and activation function tanh. Now the output size is 120. The next is a fully connected layer with 84 neurons that result in the output to 84 values and the activation function used here is again tanh. The last layer is the output layer with 10 neurons and  Softmax function.[[source]](https://www.analyticsvidhya.com/blog/2021/03/the-architecture-of-lenet-5/)

## CIFAR-10 Dataset
A very popular dataset which contains 10 different objects.   
  
![images](https://user-images.githubusercontent.com/89085916/169703589-40e18144-5f3a-4f5a-ae5f-70f43c66dfc7.jpg)
